---
title: "<img src='www/binary-logo-resize.jpg' width='240'>"
subtitle: "[binary.com](https://github.com/englianhu/binary.com-interview-question) Interview Question I - Multivariate GARCH Models"
author: "[®γσ, Lian Hu](https://englianhu.github.io/) <img src='www/ENG.jpg' width='24'> <img src='www/RYO.jpg' width='24'>®"
date: "`r lubridate::today('Asia/Tokyo')`"
output:
  html_document: 
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r setup}
suppressPackageStartupMessages(library('BBmisc'))
#'@ suppressPackageStartupMessages(library('rmsfuns'))

pkgs <- c('knitr', 'kableExtra', 'tint', 'devtools', 'lubridate', 'data.table', 'quantmod', 'tidyquant', 'plyr', 'stringr', 'magrittr', 'dplyr', 'tidyverse', 'rlist', 'memoise', 'htmltools', 'highcharter', 'googleVis', 'formattable', 'DT', 'rugarch', 'rmgarch')

suppressAll(lib(pkgs))
#'@ load_pkg(pkgs)

funs <- c('calc_fx.R', 'opt_arma.R', 'filterFX.R', 'filter_spec.R', 'mv_fx.R')
l_ply(funs, function(x) source(paste0('./function/', x)))

## Set option to below if you want to plot an independent webpage with graph 
#'@ op <- options(gvis.plot.tag=NULL)
op <- options(gvis.plot.tag = 'chart')
options(gvis.plot.tag = 'chart', warn = -1)

rm(pkgs)
```

# Introduction

From previous papers, I tried to apply few models for FOREX price forecasting and eventually got to know **Fractional Intergrated GJR-GARCH** is the best fit model as we can refer to [GARCH模型中的ARMA(p,d,q)参数最优化](http://rpubs.com/englianhu/binary-Q1FiGJRGARCH). Today I am zooming into the multivariate GARCH models.

# Data

## Read Data

Similar with **GARCH模型中的ARMA(p,d,q)参数最优化**, I use the dataset from [Binary-Q1 (Extention)](http://rpubs.com/englianhu/binary-Q1E).

```{r read-data, warning=FALSE}
cr_code <- c('AUDUSD=X', 'EURUSD=X', 'GBPUSD=X', 'CHF=X', 'CAD=X', 
             'CNY=X', 'JPY=X')

#'@ names(cr_code) <- c('AUDUSD', 'EURUSD', 'GBPUSD', 'USDCHF', 'USDCAD', 
#'@                     'USDCNY', 'USDJPY')

names(cr_code) <- c('USDAUD', 'USDEUR', 'USDGBP', 'USDCHF', 'USDCAD', 'USDCNY', 'USDJPY')

price_type <- c('Op', 'Hi', 'Lo', 'Cl')

## Read presaved Yahoo data.
mbase <- sapply(names(cr_code), function(x) readRDS(paste0('./data/', x, '.rds')) %>% na.omit)
```

```{r tidy-data1}
##数据1
fx1 <- llply(names(cr_code), function(x) {
    fls <- list.files(paste0('data/fx/', x), pattern = '^pred1')
    dfm <- ldply(fls, function(y) {
        readRDS(paste0('data/fx/', x, '/', y))
    }) %>% data.frame(Cat = 'pred1', .) %>% tbl_df
    names(dfm)[4:5] <- c('Price', 'Price.T1')
    dfm
 })
names(fx1) <- names(cr_code)

##数据2
fx2 <- llply(names(cr_code), function(x) {
    fls <- list.files(paste0('data/fx/', x), pattern = '^pred2')
    dfm <- ldply(fls, function(y) {
        readRDS(paste0('data/fx/', x, '/', y))
    }) %>% data.frame(Cat = 'pred2', .) %>% tbl_df
    names(dfm)[4:5] <- c('Price', 'Price.T1')
    dfm
 })
names(fx2) <- names(cr_code)

## Merge and tidy dataset.
fx1 %<>% ldply %>% tbl_df
fx2 %<>% ldply %>% tbl_df
fx <- suppressAll(
  bind_rows(fx1, fx2) %>% arrange(Date) %>% 
    mutate(.id = factor(.id), Cat = factor(Cat), Price.T1 = lag(Price.T1, 56)) %>% 
    dplyr::filter(Date >= ymd('2013-01-01') & Date <= ymd('2017-08-30')))

rm(fx1, fx2)
```

## Univariaite Forecast Data Error

Here I tried to look back the forecast data in previous paper **GARCH模型中的ARMA(p,d,q)参数最优化**.

```{r tidy-data2}
## Spread data.
fxm <- fx %>% separate(Type, c('Type', 'PT')) %>% 
    spread(PT, Price.T1) %>% 
    select(-Type, -Price, -Akaike, -Bayes, -Shibata, -Hannan.Quinn) %>% 
    ddply(.(.id, Cat, Date), summarise, 
              Op = na.omit(Op), 
              Hi = na.omit(Hi), 
              Lo = na.omit(Lo), 
              Cl = na.omit(Cl)) %>% tbl_df
```

```{r pred1-HiLo}
fx1 <- fxm %>% 
    mutate(diff = round(Hi - Lo, 3)) %>% 
    dplyr::filter(diff <= 0 & Cat == 'pred1')

fx1 %>% 
  kable(caption = 'Preditive Error for Univariate gjrGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*Table 2.2.1A `r paste0('[', paste(dim(fx1), collapse = ' x '), ']')` : Preditive Error for Univariate gjrGARCH.*

```{r pred2-HiLo}
fx2 <- fxm %>% 
    mutate(diff = round(Hi - Lo, 3)) %>% 
    dplyr::filter(diff <= 0 & Cat == 'pred2')

fx2 %>% 
  kable(caption = 'Preditive Error for Univariate Fi-gjrGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*Table 2.2.1B `r paste0('[', paste(dim(fx2), collapse = ' x '), ']')` : Preditive Error for Univariate Fi-gjrGARCH.*

Above *Table 2.2.1A* and *Table 2.2.1B* proof that the univariate GARCH might forecast error price due to both highest and lowest price are independence. Here I also filter the closed price as well in below tables.

```{r pred1-Cl}
fx1 <- fxm %>% 
    mutate(Range = ifelse(Cl > Hi | Cl < Lo, 0, 1)) %>% 
    dplyr::filter(Range == 0 & Cat == 'pred1')

fx1 %>% 
  kable(caption = 'Preditive Error for Univariate gjrGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*Table 2.2.2A `r paste0('[', paste(dim(fx1), collapse = ' x '), ']')` : Preditive Error for Univariate gjrGARCH.*

```{r pred2-Cl}
fx2 <- fxm %>% 
    mutate(Range = ifelse(Cl > Hi | Cl < Lo, 0, 1)) %>% 
    dplyr::filter(Range == 0 & Cat == 'pred2')

fx2 %>% 
  kable(caption = 'Preditive Error for Univariate Fi-gjrGARCH') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  scroll_box(width = '100%', height = '400px')
```

*Table 2.2.2B `r paste0('[', paste(dim(fx2), collapse = ' x '), ']')` : Preditive Error for Univariate Fi-gjrGARCH.*

From above tables, we know the univariate statistical modelling will facing statistical preditive error. Here I use the multivariate methods for further modelling.

# Modelling

## Introduce Multivariate Garch Models

  Multivariate GARCH models including DCC, GO-GARCH and Copula-GARCH.

## DCC

### Abtract of DDC

Due to article **The GARCH DCC Model and 2 Stage DCCMVT Estimation**^[Kindly refer to [Reference] for further reading.] compares the `model = c('DCC', 'aDCC')` but not `model = 'FDCC'` with all distributions and concludes that `aDCC` with `distribution = 'mvt'` is the best fit model and distribution for multivariate GARCH model. Here I directly use `mvt` but in different `solver` parameters.

```{r dcc1, echo=FALSE, eval=FALSE}
### ========= using cluster for sampling ===============
fit <- llply(na.omit(Cl(mbase[['USDJPY']])), function(x){
  
  armaOrder = opt_arma(x)
  
  xspec = ugarchspec(
    variance.model = list(
      model = 'gjrGARCH', garchOrder = c(1, 1), 
      submodel = NULL, external.regressors = NULL, 
      variance.targeting = FALSE), 
    mean.model = list(
      armaOrder = armaOrder[c(1, 3)], 
      include.mean = TRUE, archm = FALSE, 
      archpow = 1, arfima = TRUE, 
      external.regressors = NULL, 
      archex = FALSE), 
    fixed.pars = list(arfima = armaOrder[2]), 
    distribution.model = 'snorm')
    
  uspec = multispec(replicate(4, xspec))
  
  spec1 = dccspec(uspec = uspec, dccOrder = c(1, 1), 
                  model='aDCC', distribution = 'mvt')
  
  cl = makePSOCKcluster(4)
  multf = multifit(uspec, x, cluster = cl)
  
  fit1 = dccfit(spec1, data = x, solver = 'hybrid', 
                fit.control = list(eval.se = TRUE), 
                fit = multf, cluster = cl)
  
  return(fit1)
  })
```

My initially workable models result.

```{r wdcc-aic}
workable.dcc <- readRDS('data/fx/pt.dcc.rds')

#'@ dcc.AIC <- ldply(workable.dcc, function(x) {
#'@     ldply(x, function(y) {
#'@             list.select(y, AIC) %>% 
#'@             data.frame %>% t %>% data.frame %>% 
#'@             mutate(includes.Op = c(TRUE, FALSE))
#'@     }) %>% rename(.solver = .id)
#'@   }) %>% 
#'@   dplyr::select(.id, .solver, includes.Op, Akaike, Bayes, Shibata, Hannan.Quinn)

dcc.AIC <- ldply(workable.dcc, function(x) {
    zz <- ldply(x, function(y) {
        zz <- ldply(y, function(z) {
            z$AIC %>% 
            data.frame %>% t %>% data.frame
        })
        names(zz)[1] <- 'includes.Op'
        zz
    })
    names(zz)[1] <- '.solver'
    zz
  })

dcc.AIC %>% 
  kable(caption = 'Akaike Information Criteria') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  scroll_box(width = '100%', height = '400px')
```

*Table 3.2.1.1 : AIC comparison.*

From above table, `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)] %>% names` with `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)]` is the best fitted model.

```{r dcc-llh}
dcc.logLik <- ldply(workable.dcc, function(x) {
    zz = ldply(x, function(y) {
        zz = ldply(y, function(z) {
            attributes(z$fit)$mfit$llh
        })
        names(zz) <- c('includes.Op', 'log.Likelihood')
        zz
    })
    names(zz)[1] <- '.solver'
    zz
  })

dcc.logLik %>% 
  kable(caption = 'Log-Likelihood') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  scroll_box(width = '100%', height = '400px')
```

*Table 3.2.1.2 : Log-Likelihood comparison.*

### Modelling for Banker

```{r bk-dcc, eval=FALSE}
## Possible multivariate models.
md <- c('DCC', 'aDCC', 'FDCC')
sv <- c('solnp', 'nlminb', 'lbfgs', 'gosolnp')

## Includes the open price or not.
bk.base <- llply(mbase, Cl)
bk.base %<>% do.call(cbind, .) %>% na.omit

## Statistical modelling
bk.dcc <- llply(md, function(x) {
  dm <- llply(sv, function(y) {
    fit <- tryCatch(
      mv_fx(bk.base, .model = x, .solver = y, 
            .include.Op = FALSE, .Cl.only = TRUE), 
      error = function(e) cat(paste0('bk.', x, '.', y, ' error.\n')))
  
  if (!is.null('fit')) {
    eval(parse(text = paste0(
      "saveRDS(fit, 'data/fx/", paste0('bk.', x, '.', y), ".rds')")))
    cat(paste0('bk.', x, '.', y, ' saved.\n'))
  }
  })
  names(dm) <- sv
  dm
})
names(bk.dcc) <- md
```

I executed above coding and there are quite some models occured errors. The `FDCC` models do faced error even though change all possible solvers. Below I read presaved data which executed above.

```{r read-bkdcc}
fls <- list.files('data/fx', pattern = '^bk.') %>% str_replace_all('.rds', '')

bk.dcc <- sapply(fls, function(x) readRDS(paste0('data/fx/', x, '.rds'))) %>% 
  filterNull
```

Here I tried to compare the AIC values. The lowest value will be best fit model.

```{r bkdcc-aic}
##compare AIC values.
dcc.AIC <- sapply(bk.dcc, function(x) data.frame(t(x$AIC))) %>% 
    t %>% data.frame(.id = rownames(.)) %>% 
    separate(.id, c('.id', '.model', '.solver')) %>% 
    dplyr::select(.id, .model, .solver, Akaike, Bayes, Shibata, Hannan.Quinn)
rownames(dcc.AIC) <- NULL

dcc.AIC %>% 
  kable(caption = 'Akaike Information Criteria') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  scroll_box(width = '100%', height = '400px')
```

*Table 3.2.3.1 : AIC comparison.*

From above table, `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)] %>% names` with `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)]` is the best fitted model.
After that, look at the log-likehood figure as well to compare the correlation among models. The highest value will be best fit model.

```{r bkdcc-logLik}
##compare AIC values.
dcc.logLik <- sapply(bk.dcc, function(x) attributes(x$fit)$mfit$llh) %>% 
    t %>% t %>% data.frame(.id = rownames(.)) %>% 
    separate(.id, c('.id', '.model', '.solver'))
rownames(dcc.logLik) <- NULL
names(dcc.logLik)[1] <- 'log.Likelihood'
dcc.logLik %<>% dplyr::select(.id, .model, .solver, log.Likelihood)

dcc.logLik %>% 
  kable(caption = 'Log-Likelihood') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.3.2 : Log-Likelihood comparison.*

```{r bkdcc-roll}
## Possible multivariate models.
md <- c('DCC', 'aDCC', 'FDCC')
sv <- c('solnp', 'nlminb', 'lbfgs', 'gosolnp')

## Includes the open price or not.
bk.base <- llply(mbase, Cl)
bk.base %<>% do.call(cbind, .) %>% na.omit

## Statistical modelling
bk.dcc <- llply(md, function(x) {
  dm <- llply(sv, function(y) {
    fit <- tryCatch(
      mv_fx(bk.base, .model = x, .solver = y, 
            .include.Op = FALSE, .Cl.only = TRUE, .roll = TRUE), 
      error = function(e) cat(paste0('roll.bk.', x, '.', y, ' error.\n')))
  
  if (!is.null('fit')) {
    eval(parse(text = paste0(
      "saveRDS(fit, 'data/fx/", paste0('roll.bk.', x, '.', y), ".rds')")))
    cat(paste0('roll.bk.', x, '.', y, ' saved.\n'))
  }
  })
  names(dm) <- sv
  dm
})
names(bk.dcc) <- md
```


### Modelling for Punter

#### Single Currency

Multivariate modelling for single currency. Here I tried to seperate to 2 type of forecasting dataset which are `OHLC` and `HLC` to know if includes the open price will be more accurate or not.

```{r pt-dcc, eval=FALSE}
## Possible multivariate models.
md <- c('DCC', 'aDCC', 'FDCC')
sv <- c('solnp', 'nlminb', 'lbfgs', 'gosolnp')
op <- c(TRUE, FALSE)

## Includes the open price or not.
pt.base <- mbase[['USDJPY']][,1:4]

## Statistical modelling
pt.dcc <- llply(md, function(x) {
  dm <- llply(sv, function(y) {
    TF <- llply(op, function(z) {
      fit <- tryCatch(
        mv_fx(pt.base, .model = x, .solver = y, 
              .include.Op = z, .Cl.only = FALSE), 
        error = function(e) 
          cat(paste0('pt.', x, '.', y, '.', z,' error.\n')))
      
      if (!is.null('fit')) {
        eval(parse(text = paste0(
          "saveRDS(fit, 'data/fx/", 
          paste0('pt.', x, '.', y, '.', z), ".rds')")))
        cat(paste0('pt.', x, '.', y, '.', z, ' saved.\n'))
        }
    })
    names(TF) <- op
    TF
  })
  names(dm) <- sv
  dm
})
names(pt.dcc) <- md
```

I executed above coding and there are quite some models occured errors. The `FDCC` models do faced error even though change all possible solvers. Below I read presaved data which executed above.

```{r read-ptdcc}
fls <- list.files('data/fx', pattern = '^pt.[^dcc]') %>% str_replace_all('.rds', '')

pt.dcc <- sapply(fls, function(x) readRDS(paste0('data/fx/', x, '.rds'))) %>% 
  filterNull
```

Here I tried to compare the AIC values. The lowest value will be best fit model.

```{r ptdcc-aic}
##compare AIC values.
dcc.AIC <- sapply(pt.dcc, function(x) data.frame(t(data.frame(x$AIC)))) %>% 
    t %>% data.frame(.id = rownames(.)) %>% 
    separate(.id, c('.id', '.model', '.solver', 'includes.Op')) %>% 
    dplyr::select(.id, .model, .solver, includes.Op, Akaike, Bayes, Shibata, Hannan.Quinn)
rownames(dcc.AIC) <- NULL

dcc.AIC %>% 
  kable(caption = 'Akaike Information Criteria') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>%
  scroll_box(width = '100%', height = '400px')
```

*Table 3.2.4.1 : AIC comparison.*

From above table, `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)] %>% names` with `r unlist(dcc.AIC$Akaike) %>% .[which.min(.)]` is the best fitted model. After that, look at the log-likehood figure as well to compare the correlation among models. The highest value will be best fit model.

```{r ptdcc-logLik}
##compare AIC values.
dcc.logLik <- sapply(pt.dcc, function(x) attributes(x$fit)$mfit$llh) %>% 
    t %>% t %>% data.frame(.id = rownames(.)) %>% 
    separate(.id, c('.id', '.model', '.solver', 'includes.Op'))
rownames(dcc.logLik) <- NULL
names(dcc.logLik)[1] <- 'log.Likelihood'
dcc.logLik %<>% dplyr::select(.id, .model, .solver, includes.Op, log.Likelihood)

dcc.logLik %>% 
  kable(caption = 'Log-Likelihood') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))
```

*Table 3.2.4.2 : Log-Likelihood comparison.*

The model `r dcc.logLik %>% dplyr::filter(log.Likelihood == max(log.Likelihood)) %>% unite(.id, .id:includes.Op) %>% .$.id %>% str_replace_all('_', '.')` which highest logLik value `r dcc.logLik$log.Likelihood[which.max(dcc.logLik$log.Likelihood)]` is the best fitted model for correlation.

```{r ptdcc-roll}
## Possible multivariate models.
md <- c('DCC', 'aDCC', 'FDCC')
sv <- c('solnp', 'nlminb', 'lbfgs', 'gosolnp')
op <- c(TRUE, FALSE)

## Includes the open price or not.
pt.base <- mbase[['USDJPY']][,1:4]

## Statistical modelling
pt.dcc <- llply(md, function(x) {
  dm <- llply(sv, function(y) {
    TF <- llply(op, function(z) {
      fit <- tryCatch(
        mv_fx(pt.base, .model = x, .solver = y, 
              .include.Op = z, .Cl.only = FALSE, .roll = TRUE), 
        error = function(e) 
          cat(paste0('roll.pt.', x, '.', y, '.', z,' error.\n')))
      
      if (!is.null('fit')) {
        eval(parse(text = paste0(
          "saveRDS(fit, 'data/fx/", 
          paste0('roll.pt.', x, '.', y, '.', z), ".rds')")))
        cat(paste0('roll.pt.', x, '.', y, '.', z, ' saved.\n'))
        }
    })
    names(TF) <- op
    TF
  })
  names(dm) <- sv
  dm
})
names(pt.dcc) <- md
```

**VAR and Robust**

Above models set `VAR=TRUE` and `robust=FALSE`, now I based on above best fitted model and adjust the parameter to test if it is more accurate.

```{r dcc-var, eval=FALSE}
.VARs = c(TRUE, FALSE)
.rb = c(TRUE, FALSE)


```


#### Currency Basket

Nested multivariate modelling for a basket of currencies.

## GO-GARCH

```{r go-garch1, eval=FALSE}

.dist.models <- c('mvnorm', 'manig', 'magh')

## attributes of univariate stage 1
attributes(attributes(fit)$mfit$ufit)

## attributes of univariate stage 2
names(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[1]])$fit)
names(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[2]])$fit)
names(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[3]])$fit)

## AIC
-2*as.numeric(logLik(fit))+2*(length(fit$coefficients)+1)

-2 * as.numeric(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[1]])$fit$LLH) + 2*(length(attributes(attributes(attributes(fit)$mfit$ufit)[[1]][[1]])$fit$coef) + 1)
```

## Copula-GARCH


# Conclusion


```{r stopPar, echo = FALSE}
## Set options back to original options
options(op)
options(warn = 0)
```

# Appendix

## Documenting File Creation 

It's useful to record some information about how your file was created.

- File creation date: 2017-10-17
- File latest updated date: `r today('Asia/Tokyo')`
- `r R.version.string`
- R version (short form): `r getRversion()`
- [**rmarkdown** package](https://github.com/rstudio/rmarkdown) version: `r packageVersion('rmarkdown')`
- File version: 1.0.1
- Author Profile: [®γσ, Eng Lian Hu](https://beta.rstudioconnect.com/content/3091/ryo-eng.html)
- GitHub: [Source Code](https://github.com/englianhu/binary.com-interview-question)
- Additional session information:

```{r info, echo = FALSE, warning = FALSE, results = 'asis'}
suppressMessages(require('dplyr', quietly = TRUE))
suppressMessages(require('formattable', quietly = TRUE))

sys1 <- devtools::session_info()$platform %>% unlist %>% data.frame(Category = names(.), session_info = .)
rownames(sys1) <- NULL

sys1 %<>% rbind(., data.frame(Category = 'Current time', session_info = paste(as.character(now('Asia/Tokyo')), 'JST')))

sys2 <- data.frame(Sys.info()) %>% mutate(Category = rownames(.)) %>% .[2:1]
names(sys2)[2] <- c('Sys.info')
rownames(sys2) <- NULL

cbind(sys1, sys2) %>% 
  kable(caption = 'Additional session information:') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive'))

rm(sys1, sys2)
```

## Reference

01. [Betting Strategy and Model Validation - Part II](https://englianhu.github.io/2017/10/Betting_Strategy_and_Model_Validation_-_Part_02/)
02. [**binary.com Job Application - Quantitative Analyst** *sample question*](https://github.com/englianhu/binary.com-interview-question)
03. [GARCH模型中的`ARMA(p,d,q)`参数最优化](http://rpubs.com/englianhu/binary-Q1FiGJRGARCH)
04. [The `rmgarch` Models - Background and Properties](https://raw.githubusercontent.com/englianhu/binary.com-interview-question/master/reference/The%20rmgarch%20Models%20-%20Background%20and%20Properties.pdf)
05. [Financial Econometrics Practical - Univariate Volatility Modelling](https://raw.githubusercontent.com/englianhu/binary.com-interview-question/master/reference/Financial%20Econometrics%20Practical%20-%20Univariate%20Volatility%20Modelling.pdf)
06. [The GARCH-DCC Model and 2-Stage DCC(MVT) Estimation](http://www.unstarched.net/2013/01/03/the-garch-dcc-model-and-2-stage-dccmvt-estimation/)
07. [Multivariate Volatility Forecasting, Part 2 – Equicorrelation](https://eranraviv.com/multivariate-volatility-forecasting-2/)

---

**Powered by - Copyright® Intellectual Property Rights of <img src='www/oda-army2.jpg' width='24'> [Scibrokes®](http://www.scibrokes.com)個人の経営企業**
